import argparse
import ctypes
import json
import os
import subprocess

import torch

from evaluation.macros import CUDA_MACROS as macro
from evaluation.utils import run_cuda_compilation as run_compilation


def parse_config(config_input):
    """
    Parse config: either a JSON string or a file path
    Expected format:
    {
        "op_name": "sum",
        "dtype": "float32",
        "args": [3, 4, 5],        # input shape
        "axes": [0] or 0          # reduction axes
    }
    """
    if os.path.isfile(config_input):
        with open(config_input, "r") as f:
            config = json.load(f)
    else:
        config = json.loads(config_input)

    shape = config["args"]
    axes = config["axes"]
    if isinstance(axes, int):
        axes = [axes]
    return shape, axes


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--file",
        type=str,
        required=True,
        help="Path to the C++ source file (e.g., sum_3_4_5.cu)",
    )
    parser.add_argument(
        "--config", required=True, help="JSON string or path to kernel config"
    )
    parser.add_argument(
        "--target",
        required=True,
        choices=["cuda", "hip", "mlu", "cpu"],
        help="Target platform",
    )
    args = parser.parse_args()

    base_name = os.path.basename(args.file)
    name = base_name.split("_")[0]  # e.g., "sum"
    shapes_str = base_name.replace(".cu", "")
    # Dynamically extract shape: parse all numbers from filename
    try:
        shape_from_filename = [int(x) for x in shapes_str.split("_")[1:]]
    except ValueError:
        raise ValueError(
            f"Invalid filename format: {args.file}. Expected: op_M_N_K.cu"
        )

    # Get the true shape and axes from config
    config_shape, axes = parse_config(args.config)

    print(
        f"üîç Testing {name.upper()} with input shape {config_shape}, axes={axes}"
    )

    # ‚úÖ ‰ΩøÁî® config ‰∏≠ÁöÑ shapeÔºåËÄåÈùûÊñá‰ª∂ÂêçÔºàÊõ¥ÂèØÈù†Ôºâ
    shape = config_shape

    # ‚úÖ Generate input tensor
    A = torch.rand(shape, device="cpu", dtype=torch.float32)

    # ‚úÖ ÈªÑÈáëÊ†áÂáÜÔºöÊ≤øÊåáÂÆö axes Ê±ÇÂíåÔºå‰∏ç‰øùÁïôdimÔºà‰∏éÂ§ßÂ§öÊï∞ kernel ‰∏ÄËá¥Ôºâ
    expected_tensor = torch.sum(A, dim=axes)  # shape: reduced
    expected_numpy = expected_tensor.numpy()
    expected_flat = expected_numpy.flatten()

    # ‚úÖ ËæìÂÖ•ÊåáÈíàÔºàÂ±ïÂπ≥ËæìÂÖ•Ôºâ
    A_flat = A.numpy()  # Ëá™Âä®Â±ïÂπ≥‰∏∫ C È°∫Â∫è
    A_ptr = A_flat.ctypes.data_as(ctypes.POINTER(ctypes.c_float))

    # ‚úÖ outputÂ§ßÂ∞è
    output_size = expected_flat.size  # int
    result_array = (ctypes.c_float * output_size)()  # ÂàÜÈÖçÁ©∫Èó¥

    # shared library
    so_name = args.file.replace(".cu", ".so")

    # LoadÂéüÂßã‰ª£Á†Å
    with open(args.file, "r") as f:
        code = f.read()

    code = macro + code

    # Create tmp file
    temp_file_name = args.file.replace(".cu", "_bak.cu")
    with open(temp_file_name, "w") as f:
        f.write(code)

    # compile
    print(f"‚öôÔ∏è Compiling {temp_file_name} -> {so_name}")
    success, compile_output = run_compilation(so_name, temp_file_name)
    if not success:
        print("‚ùå Compilation failed:")
        print(compile_output)
        exit(1)

    os.remove(temp_file_name)

    # load shared library
    lib = ctypes.CDLL(os.path.join(os.getcwd(), so_name))
    kernel_func = getattr(lib, name + "_kernel")

    # ‚úÖ Function  signature
    kernel_func.argtypes = [
        ctypes.POINTER(ctypes.c_float),  # input
        ctypes.POINTER(ctypes.c_float),  # output
    ]
    kernel_func.restype = None

    # ‚úÖ invoke kernel
    print(f"üöÄ Running {name.upper()} kernel...")
    kernel_func(A_ptr, result_array)

    # ‚úÖ Get output
    computed_array = [result_array[i] for i in range(output_size)]
    computed_tensor = torch.tensor(computed_array).view_as(
        torch.from_numpy(expected_numpy)
    )

    # ‚úÖ verification
    abs_diff = torch.abs(computed_tensor - expected_tensor)
    max_error = abs_diff.max().item()

    if max_error <= 1e-3:
        print(f"‚úÖ Verification successful! C++ sum matches PyTorch.")
        print(f"   Output shape: {tuple(expected_tensor.shape)}")
        # ÂèØÈÄâÔºöÊâìÂç∞ÂâçÂá†‰∏™ÂÄº
        if output_size <= 10:
            for i, (exp, got) in enumerate(zip(expected_flat, computed_array)):
                print(f"   Index {i}: Expected: {exp:.6f}, Got: {got:.6f}")
    else:
        print(f"‚ùå Verification failed! Max error = {max_error:.2e}")
        print(f"   Expected shape: {expected_tensor.shape}")
        print(f"   Computed shape: {computed_tensor.shape}")
        exit(1)

    # clean
    subprocess.run(["rm", so_name], check=False)
